{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR / VLM pipeline launcher (Colab)\n",
    "\n",
    "This notebook installs dependencies, clones the repo, and runs the pipeline in `pipeline_mode: vlm|hybrid|classic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 0. GPU check\n",
    "import torch, platform, os, subprocess, json\n",
    "print(\"Python\", platform.python_version())\n",
    "print(\"Torch CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Clone repo (set your URL)\n",
    "import os, shutil, subprocess, json\n",
    "\n",
    "REPO_URL = \"https://github.com/smidolt/x.git\"  #@param {type:\"string\"}\n",
    "TARGET_DIR = \"/content/OCR\"  #@param {type:\"string\"}\n",
    "\n",
    "if os.path.exists(TARGET_DIR):\n",
    "    print(f\"Removing existing {TARGET_DIR}...\")\n",
    "    shutil.rmtree(TARGET_DIR)\n",
    "\n",
    "print(f\"Cloning {REPO_URL} -> {TARGET_DIR}\")\n",
    "subprocess.check_call([\"git\", \"clone\", REPO_URL, TARGET_DIR])\n",
    "os.chdir(TARGET_DIR)\n",
    "print(\"Repo ready:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 2. Install system deps (tesseract/poppler for pdf2image)\n",
    "!apt-get update -qq && apt-get install -y -qq tesseract-ocr poppler-utils > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Install Python deps (classic + VLM)\n",
    "!pip install -U pip\n",
    "!pip install -r requirements.txt\n",
    "!pip install -r requirements-vlm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Configure pipeline mode\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "CONFIG_PATH = Path(\"config.yaml\")\n",
    "with CONFIG_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# Example: VLM reasoner on GPU; disable LayoutLM when not needed\n",
    "cfg[\"pipeline_mode\"] = \"vlm\"  # options: classic | vlm | hybrid\n",
    "cfg.setdefault(\"vlm\", {})\n",
    "cfg[\"vlm\"].update({\n",
    "    \"enabled\": True,\n",
    "    \"backend\": \"qwen2_vl\",  # heuristic | qwen2_vl\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"max_new_tokens\": 256,\n",
    "})\n",
    "cfg.setdefault(\"layoutlm\", {})\n",
    "cfg[\"layoutlm\"][\"enabled\"] = False  # avoid loading when in vlm-only mode\n",
    "\n",
    "with CONFIG_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(cfg, f, sort_keys=False, allow_unicode=True)\n",
    "print(\"Updated config.yaml:\")\n",
    "print(yaml.safe_dump(cfg, sort_keys=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Run pipeline\n",
    "!python -m src.cli --config config.yaml --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6. Inspect outputs\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "out_dir = Path(\"output/json\")\n",
    "for path in sorted(out_dir.glob(\"*.json\")):\n",
    "    print(\"-\", path.name)\n",
    "    data = json.loads(path.read_text())\n",
    "    print(\"  keys:\", list(data.keys()))\n",
    "    print(\"  classic present:\", \"classic\" in data, \"vlm present:\", \"vlm\" in data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
