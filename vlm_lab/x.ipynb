{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a78396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "{'type': 'cuda', 'index': 0, 'name': 'NVIDIA A100-SXM4-40GB', 'capability': (8, 0)}\n",
      "{'type': 'cpu', 'index': 0, 'name': 'CPU'}\n",
      "Default tensor device: cpu\n",
      "Chosen device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device diagnostics (CPU/CUDA/MPS)\n",
    "import torch\n",
    "\n",
    "def available_devices():\n",
    "    devices = []\n",
    "    if torch.cuda.is_available():\n",
    "        for idx in range(torch.cuda.device_count()):\n",
    "            name = torch.cuda.get_device_name(idx)\n",
    "            cap = torch.cuda.get_device_capability(idx)\n",
    "            devices.append({\"type\": \"cuda\", \"index\": idx, \"name\": name, \"capability\": cap})\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        devices.append({\"type\": \"mps\", \"index\": 0, \"name\": \"Apple MPS\"})\n",
    "    devices.append({\"type\": \"cpu\", \"index\": 0, \"name\": \"CPU\"})\n",
    "    return devices\n",
    "\n",
    "devices = available_devices()\n",
    "print(\"Available devices:\")\n",
    "for d in devices:\n",
    "    print(d)\n",
    "\n",
    "x = torch.tensor([1.0])\n",
    "print(\"Default tensor device:\", x.device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Chosen device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf2c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matmul done on cuda result shape torch.Size([1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Optional: quick smoke test with torch matrix multiply to verify the device runs\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "a = torch.randn(1024, 1024, device=device)\n",
    "b = torch.randn(1024, 1024, device=device)\n",
    "with torch.inference_mode():\n",
    "    c = a @ b\n",
    "print(\"Matmul done on\", device, \"result shape\", c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a979dfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python /content/run_poc.py --documents /data/input --models-file /content/models.yaml --output-dir /content/results --max-pages 1 --device cuda\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " python3: can't open file '/content/run_poc.py': [Errno 2] No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run VLM PoC from notebook (uses GPU if available)\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "# Try to locate repo root flexibly\n",
    "cwd = Path.cwd().resolve()\n",
    "repo = cwd if (cwd / 'run_poc.py').exists() else cwd / 'vlm_lab'\n",
    "if not (repo / 'run_poc.py').exists():\n",
    "    # fallback: assume notebook is inside vlm_lab\n",
    "    repo = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "python_bin = repo / '.venv/bin/python'\n",
    "python_exec = python_bin if python_bin.exists() else 'python'\n",
    "models_file = repo / 'models.yaml'\n",
    "documents = repo.parent / 'data/input'\n",
    "output_dir = repo / 'results'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'auto'\n",
    "\n",
    "cmd = [\n",
    "    str(python_exec),\n",
    "    str(repo / 'run_poc.py'),\n",
    "    '--documents', str(documents),\n",
    "    '--models-file', str(models_file),\n",
    "    '--output-dir', str(output_dir),\n",
    "    '--max-pages', '1',\n",
    "    '--device', device,\n",
    "]\n",
    "\n",
    "print('Running:', ' '.join(cmd))\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print('STDOUT:\\n', result.stdout)\n",
    "print('STDERR:\\n', result.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
