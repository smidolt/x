{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM invoice validation bench (Colab)\n",
    "\n",
    "Просто запускай ячейки сверху вниз: установка зависимостей, загрузка payload, прогон моделей. Репозиторий ожидается в `/content/OCR`; если путь другой — поправь `repo_path` ниже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate bitsandbytes\n",
    "# Для Llama 3.1 нужен HF токен:\n",
    "# from huggingface_hub import login; login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib, sys\n",
    "repo_path = pathlib.Path('/content/OCR')\n",
    "if not repo_path.exists():\n",
    "    raise RuntimeError('Смонтируй/распакуй репозиторий в /content/OCR или поправь repo_path')\n",
    "sys.path.insert(0, str(repo_path))\n",
    "from src.llm.runner import load_payload, run_model\n",
    "from src.llm.models import MODEL_REGISTRY\n",
    "\n",
    "payload_path = repo_path / 'src/llm/data/sample_payload.json'\n",
    "payload = load_payload(payload_path)\n",
    "out_dir = repo_path / 'src/llm/data/out'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_keys = [\n",
    "    'llama31-8b', 'llama31-70b', 'qwen2-7b', 'qwen2-72b',\n",
    "    'mistral-7b', 'mixtral-8x7b', 'deepseek-7b', 'phi3-medium'\n",
    "]\n",
    "print('Will run models:', model_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for key in model_keys:\n",
    "    print(f'>>> Running {key}')\n",
    "    res = run_model(key, payload, max_new_tokens=512, temperature=0.2)\n",
    "    out_path = out_dir / f'{key}.json'\n",
    "    out_path.write_text(json.dumps(res, indent=2, ensure_ascii=False), encoding='utf-8')\n",
    "    results[key] = out_path.as_posix()\n",
    "\n",
    "print('Saved outputs:')\n",
    "print(json.dumps(results, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
