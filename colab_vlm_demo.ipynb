{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VLM demo (Colab, Qwen2-VL)\n",
        "- Clones repo `https://github.com/smidolt/x.git`\n",
        "- Installs deps\n",
        "- Runs **only VLM** on `input/google.jpg` (или замени на свой файл)\n",
        "- Генерирует JSON ответ (пытаемся строго JSON промптом)\n",
        "\n",
        "> Можно менять модель: `Qwen/Qwen2-VL-7B-Instruct` (стабильнее, но тяжелее) или `Qwen/Qwen2-VL-2B-Instruct`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        # Clone repo\n",
        "!rm -rf /content/x && git clone https://github.com/smidolt/x.git /content/x\n",
        "%cd /content/x\n",
        "\n",
        "# Install deps (VLM + basics)\n",
        "!pip install -r requirements.txt -r requirements-vlm.txt\n",
        "\n",
        "# Tesseract обычно уже есть в Colab; если нужно:\n",
        "# !apt-get update && apt-get install -y tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        # Choose input image\n",
        "from pathlib import Path\n",
        "\n",
        "img_path = Path('input/google.jpg')  # put your file here if different\n",
        "if not img_path.exists():\n",
        "    raise FileNotFoundError(f\"No image found at {img_path}, upload or change path\")\n",
        "print(\"Using image:\", img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        # Run VLM reasoner ONLY (no preprocess/OCR). Uses service wrapper.\n",
        "import json\n",
        "from src.vlm.services import run_reasoner\n",
        "\n",
        "# Model to try: 'Qwen/Qwen2-VL-7B-Instruct' (more stable) or 'Qwen/Qwen2-VL-2B-Instruct' (lighter)\n",
        "model_name = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
        "\n",
        "custom_prompt = (\n",
        "    \"Return ONLY valid JSON with keys: meta, items, notes. Example: \"\n",
        "    '{\"meta\": {\"seller_name\": \"...\", \"buyer_name\": \"...\", \"invoice_number\": \"...\", \"currency\": \"...\", \"total_net\": ..., \"total_vat\": ..., \"total_gross\": ...}, '\n",
        "    '\"items\": [{\"description\": \"...\", \"quantity\": ..., \"unit_price\": ..., \"amount\": ..., \"currency\": \"...\"}], \"notes\": []}'\n",
        ")\n",
        "\n",
        "res = run_reasoner({\n",
        "    \"image_path\": str(img_path),\n",
        "    \"params\": {\n",
        "        \"model_name\": model_name,\n",
        "        \"device\": \"auto\",\n",
        "        \"max_new_tokens\": 128,\n",
        "        \"temperature\": 0,\n",
        "        \"prompt\": custom_prompt,\n",
        "        # generation tweaks (enable sampling to avoid '!!!!')\n",
        "        \"do_sample\": True,\n",
        "        \"top_p\": 0.9,\n",
        "        \"top_k\": 50,\n",
        "    }\n",
        "})\n",
        "\n",
        "print(\"Elapsed:\", res.get(\"elapsed_seconds\"))\n",
        "print(\"Error:\", res.get(\"error\"))\n",
        "print(\"Raw response:\\n\", res.get(\"raw_response\", \"\")[:1000])\n",
        "\n",
        "output_path = Path(\"output_vlm_single.json\")\n",
        "output_path.write_text(json.dumps(res, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
        "print(\"Saved:\", output_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
